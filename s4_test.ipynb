{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qhduan/Work/cpu/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from s3_train import build_model\n",
    "from utils import MAX_LENGTH, LABEL_DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_ld = {v: k for k, v in LABEL_DICT.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open('data.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = pickle.load(open('ws.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (MAX_LENGTH,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/qhduan/Work/cpu/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1238: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/qhduan/Work/cpu/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1255: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/qhduan/Work/cpu/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1340: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 200)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 200, 64)      648576      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 200, 64)      0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     (None, 200, 32)      9312        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gru_2 (GRU)                     (None, 200, 32)      6240        gru_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 6400)         0           gru_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 200)          1280200     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 32, 200)      0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 200, 32)      0           repeat_vector_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 200, 32)      0           gru_2[0][0]                      \n",
      "                                                                 permute_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 6400)         0           multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_1 (GaussianNoise (None, 6400)         0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 300)          1920300     gaussian_noise_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 300)          1200        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 300)          0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 300)          0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 300)          90300       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 300)          1200        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 300)          0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 300)          0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 6)            1806        dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,959,134\n",
      "Trainable params: 3,957,934\n",
      "Non-trainable params: 1,200\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model, atten_model = build_model(shape, len(ws))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./model_gru_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(sentence):\n",
    "    vec = ws.transform(sentence, MAX_LENGTH)\n",
    "#     print(vec)\n",
    "    x = np.array([vec])\n",
    "    pred = model.predict(x)\n",
    "    atten = atten_model.predict(x)\n",
    "    atten = atten.reshape((MAX_LENGTH, 32))\n",
    "    atten = np.sum(atten, axis=-1)\n",
    "    print(atten.shape)\n",
    "    \n",
    "    ret = []\n",
    "    for i in range(len(LABEL_DICT)):\n",
    "        ret.append((\n",
    "            inverse_ld[i],\n",
    "            pred[0][i] * 100\n",
    "        ))\n",
    "    ret = sorted(ret, key=lambda x: x[1], reverse=True)\n",
    "    for r in ret:\n",
    "        print('{}\\t\\t{:.2f}%'.format(\n",
    "            r[0],\n",
    "            r[1]\n",
    "        ))\n",
    "#     for i, w in enumerate(list(sentence)):\n",
    "#         print(atten[i], w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_test(data, max_length=MAX_LENGTH):\n",
    "    while True:\n",
    "        ind = np.random.randint(0, len(data))\n",
    "        x = data[ind][0]\n",
    "        y = data[ind][2]\n",
    "        if len(x) <= max_length:\n",
    "            break\n",
    "    print(x)\n",
    "    print(y)\n",
    "    test(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "戴老师所言极是，我家每天的米饭都是大米，玉米渣，高粱米，荞麦米，小黄米，紫米搭配的，另外再加点紫薯块和南瓜块，老公天天说，想吃点白米饭怎么那么难呢，，其实这样搭配的另外一个好处就是，粗粮，饱腹感很强，可以抑制食欲\n",
      "happy\n",
      "(200,)\n",
      "happy\t\t30.01%\n",
      "disgust\t\t22.97%\n",
      "angry\t\t21.95%\n",
      "sad\t\t10.85%\n",
      "fear\t\t9.62%\n",
      "suprise\t\t4.60%\n",
      "各种笑容的英文表达，smile（微笑）、laugh（大笑）、grin（露齿而笑）、chuckle（轻笑）、smirk（得意地笑）、simper（痴笑）、snicker（坏笑）、giggle（咯咯笑）、titter（）、guffaw（狂笑）、roar（哄笑）、chortle（欢笑）、ridicule（嘲笑）、deride（讥笑）\n",
      "happy\n",
      "(200,)\n",
      "happy\t\t88.83%\n",
      "disgust\t\t4.43%\n",
      "fear\t\t2.33%\n",
      "sad\t\t2.01%\n",
      "angry\t\t1.74%\n",
      "suprise\t\t0.67%\n",
      "爲了兩件垃圾系度同我講錢仲要問候埋我娘親求你都系多餘，個晚擔心你安危都系多7魚，仲講乜野朋友我呸呸甘多年10年我都未講耐1000蚊買起你人格，講錢傷感情，講到錢乜野兄弟朋友都無得做，全部通通走開，全都爲個區區臭錢，從今開始互不借錢，終於明白咩叫借錢如送禮，還錢如乞米\n",
      "angry\n",
      "(200,)\n",
      "angry\t\t69.69%\n",
      "disgust\t\t10.22%\n",
      "sad\t\t8.71%\n",
      "suprise\t\t4.87%\n",
      "fear\t\t4.67%\n",
      "happy\t\t1.84%\n",
      "很久没看電視，今晚看到碧X洗衣液的廣告，還＂粉絲鄰居＂呢，配合小S＂不裝B會死＂的表情，感覺真賤啊\n",
      "happy\n",
      "(200,)\n",
      "happy\t\t45.63%\n",
      "disgust\t\t17.55%\n",
      "angry\t\t14.33%\n",
      "sad\t\t10.81%\n",
      "fear\t\t8.83%\n",
      "suprise\t\t2.86%\n",
      "回复这是我自己猜猜的，说是超级大腕律师，肯定非同一般，又是专业律师，又安排元月四号讲座，再结合往年的建纬与大成的接触，可想而知的。我估计就是他。你现在可以去大成挖一个更大的过来，比如把挖过来，，刘不是要辞去主任啦？机会啊 。\n",
      "happy\n",
      "(200,)\n",
      "happy\t\t45.16%\n",
      "disgust\t\t20.94%\n",
      "fear\t\t12.70%\n",
      "suprise\t\t7.41%\n",
      "angry\t\t7.27%\n",
      "sad\t\t6.53%\n",
      "这家KTV真心不错啊~老王一Sukey是围脖菜鸟 玩夹娃娃一夹即中还送我了，理由是觉得Hello Kitty不好看，我屁颠屁颠地要了，心花怒放了一路啊我知道你是故意要送我的，这么好的女人哪里去找啊~ 另外还要感谢一宇宙人萊斯麗張丁丁 你那时推荐过这间！！！ \n",
      "happy\n",
      "(200,)\n",
      "happy\t\t61.16%\n",
      "fear\t\t11.02%\n",
      "sad\t\t10.59%\n",
      "disgust\t\t10.23%\n",
      "angry\t\t5.04%\n",
      "suprise\t\t1.96%\n",
      "以前提到结婚，想到「天长地久」；现在提到结婚，想到「能撑多久」。当初会结婚，说是「看上眼」；后来会离婚，说是「看走眼」。婚前，爱情是神话；婚后，爱情是笑话。女人花钱，是因为男人让她不高兴；男人花钱，是为了让女人高兴。\n",
      "happy\n",
      "(200,)\n",
      "happy\t\t72.67%\n",
      "disgust\t\t10.44%\n",
      "fear\t\t6.53%\n",
      "sad\t\t4.32%\n",
      "angry\t\t3.75%\n",
      "suprise\t\t2.29%\n",
      "写给什么都不懂的，即将陪男友一起看片的妹纸，复仇者战队由美国队长，钢铁侠，雷神，绿巨人，鹰眼，斯嘉丽大波妹组成，复仇者的意思就是你丫别招我，招了我我就跟你丫死磕到底的意思。\n",
      "disgust\n",
      "(200,)\n",
      "happy\t\t53.88%\n",
      "disgust\t\t15.00%\n",
      "angry\t\t11.77%\n",
      "sad\t\t9.42%\n",
      "fear\t\t7.74%\n",
      "suprise\t\t2.20%\n",
      "春光明媚中，特别适合二，纷扰沉重，独你缺心眼。心眼有时必须缺，看着那帮心眼多的人跟那儿没完没了算计，你该庆幸自己缺心眼，你该觉得自己二得有人味。清水出二逼，天然缺心眼---李白的诗写得就是好。---大仙\n",
      "happy\n",
      "(200,)\n",
      "happy\t\t38.07%\n",
      "sad\t\t19.06%\n",
      "disgust\t\t15.52%\n",
      "fear\t\t14.55%\n",
      "angry\t\t9.98%\n",
      "suprise\t\t2.82%\n",
      "【唯一视觉·七夕】七夕情人节你要怎么过？路过 略过 哭过 笑过 吃过 喝过 醉过 疯过 睡过 难过 一笑而过 擦肩而过 租个人过 闭门思过 爱咋过咋过 怎么高兴怎么过~【时尚婚纱照、韩式清新照、一切尽在唯一视觉】 \n",
      "fear\n",
      "(200,)\n",
      "happy\t\t66.56%\n",
      "disgust\t\t11.22%\n",
      "fear\t\t9.67%\n",
      "sad\t\t5.74%\n",
      "angry\t\t3.83%\n",
      "suprise\t\t2.97%\n",
      "【白领适合菊花茶】菊花沏茶尤其适合上班族多喝，菊花里含有丰富的维生素A，是维护眼睛健康的重要物质。菊花茶对肝火旺、用眼过度导致的双眼干涩有较好的疗效，眼睛近视的人更是经常感到眼睛干涩，喝菊花茶能改善眼睛的不舒服，对眼睛疲劳、视力模糊有很好的疗效\n",
      "angry\n",
      "(200,)\n",
      "happy\t\t37.21%\n",
      "disgust\t\t19.23%\n",
      "fear\t\t18.96%\n",
      "suprise\t\t13.55%\n",
      "sad\t\t6.08%\n",
      "angry\t\t4.97%\n",
      "一杨姓编剧外出写戏，对方接待殷勤， 一口一个“杨编”叫得甚是亲热。哥们听着不舒服，请他们换个称呼。第二天大家都改口称他为“杨剧”，杨编剧崩溃了。。。\n",
      "happy\n",
      "(200,)\n",
      "happy\t\t46.54%\n",
      "disgust\t\t17.70%\n",
      "angry\t\t11.75%\n",
      "sad\t\t10.87%\n",
      "fear\t\t9.97%\n",
      "suprise\t\t3.18%\n",
      "古装武侠巨制《》第一波高清剧照曝光——“刀客”傅红雪：@钟汉良！他叫红雪，是因为出生当天的流血，将满地的雪都染红。上天是残忍的，给他一出生就安排了一场惨绝的大屠杀。@华策影视@电视剧天涯明月刀@钟汉良官方网站\n",
      "sad\n",
      "(200,)\n",
      "angry\t\t33.80%\n",
      "disgust\t\t19.72%\n",
      "sad\t\t18.74%\n",
      "fear\t\t14.17%\n",
      "suprise\t\t7.09%\n",
      "happy\t\t6.49%\n",
      "【父亲对孩子影响】1、性别认同：父亲是男孩最重要的典范，是女孩对异性看法的基础2、自我认同：儿时没得到父亲赞美和肯定，长大会自卑和焦虑3、价值观：母亲在婴幼儿期特别重要，父亲在儿童期特别重要儿童期望成为像父亲那样的人所以爸爸们要加油啊！ \n",
      "happy\n",
      "(200,)\n",
      "happy\t\t44.45%\n",
      "fear\t\t20.82%\n",
      "sad\t\t18.37%\n",
      "disgust\t\t9.56%\n",
      "angry\t\t4.28%\n",
      "suprise\t\t2.51%\n",
      "Cindy在唱come on在看Hito頒獎禮 除了金曲獎 我已經很少會看直播頒獎禮了 這個有很多紅星 (當然我家杰倫是重點) 也蠻具指標性  只是，電腦上不了微博是什麼一回事\n",
      "angry\n",
      "(200,)\n",
      "happy\t\t59.12%\n",
      "disgust\t\t13.67%\n",
      "sad\t\t8.73%\n",
      "angry\t\t8.66%\n",
      "fear\t\t7.76%\n",
      "suprise\t\t2.05%\n",
      "这是我今天听到的最惊悚的消息，MMJ你这得伤了多少高帅富的心啊!一万四一条牛仔裤你在中国卖的哗哗的，你说你干吗非跟个共产主义者合作?的理想跟金胖子一样，丫可是想让全国人民穿上LV的疯B啊!／／花哥 今天看到mmj都开始和凡客联名合作了 想起你以前说的对外收购 品牌不靠谱 要以资源性为主\n",
      "sad\n",
      "(200,)\n",
      "disgust\t\t27.24%\n",
      "angry\t\t24.49%\n",
      "suprise\t\t19.91%\n",
      "fear\t\t13.45%\n",
      "sad\t\t9.31%\n",
      "happy\t\t5.60%\n",
      "一大早，分享一个安静的书房，新中式的风格，有点被穿越了的味道，其实重点在墙上的那四个字：！各位日日忙碌的童鞋们，努力工作吧，为自己、为理想、为家人、为生活……\n",
      "happy\n",
      "(200,)\n",
      "happy\t\t58.72%\n",
      "sad\t\t11.47%\n",
      "disgust\t\t11.35%\n",
      "fear\t\t10.59%\n",
      "angry\t\t5.91%\n",
      "suprise\t\t1.96%\n",
      "，你就继续舔恒大吧，去广州住顶级酒店？免费？还报销找小姐的钱？达10哪不如孔卡？前锋进球才是王道！什么位置干什么事。孔卡拿着欧洲一线球员的年薪他就应该有那样的表现。别再BB了。\n",
      "happy\n",
      "(200,)\n",
      "disgust\t\t28.87%\n",
      "happy\t\t25.97%\n",
      "angry\t\t21.36%\n",
      "fear\t\t8.38%\n",
      "suprise\t\t8.10%\n",
      "sad\t\t7.32%\n",
      "俄罗斯方块告诉我们：犯下的错误会积累，获得的成功会消失；植物大战僵尸告诉我们：须常调整状态，方能应付不同挑战；愤怒的小鸟告诉我们：有时沉下身心，是为了飞的更高；跑跑卡丁车告诉我们：永远别觉得时间还多，可以浪费；爱情公寓告诉我们，爱情友情、基情恋情，有时太难区分~\n",
      "happy\n",
      "(200,)\n",
      "happy\t\t24.92%\n",
      "disgust\t\t19.99%\n",
      "sad\t\t18.64%\n",
      "fear\t\t17.95%\n",
      "angry\t\t13.40%\n",
      "suprise\t\t5.10%\n",
      "我们的国家，我们要说话才对！/我们的生活总被赋予悲凉的新意，有人不过为了同工同酬，就进了精神病院；有人不过想吃顿安全的饭菜，被逼成了化学家；有人不过是深爱着他的家，却走在了卖国的路上。所以这里的荒诞并不是荒诞，而是一种荒诞必演化成另一种荒诞。\n",
      "sad\n",
      "(200,)\n",
      "sad\t\t53.83%\n",
      "fear\t\t27.38%\n",
      "happy\t\t5.87%\n",
      "disgust\t\t5.71%\n",
      "angry\t\t4.58%\n",
      "suprise\t\t2.63%\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    random_test(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
